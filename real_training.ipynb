{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation, Resizing, Rescaling\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GaussianNoise\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 299, 299\n",
    "train_data_dir = 'Training'\n",
    "validation_data_dir = 'Testing'\n",
    "test_data_dir = 'Validation'\n",
    "nb_train_samples = 7470 \n",
    "nb_validation_samples = 1511\n",
    "batch_size = 64\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.keras.utils.image_dataset_from_directory(train_data_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            label_mode='categorical',\n",
    "                                                            image_size=(img_height, img_width),)\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_data_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            label_mode='categorical',\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            image_size=(img_height, img_width),)\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(test_data_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            label_mode='categorical',\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            image_size=(img_height, img_width),)\n",
    "\n",
    "training_batches = tf.data.experimental.cardinality(training_dataset)\n",
    "validation_batches = tf.data.experimental.cardinality(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = training_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "# test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  # tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Resizing(img_height, img_width),\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  # tf.keras.layers.RandomRotation(0.2),\n",
    "  tf.keras.layers.RandomZoom(0.2),\n",
    "  tf.keras.layers.RandomContrast(0.2),\n",
    "  tf.keras.layers.RandomBrightness(0.2),\n",
    "  # tf.keras.layers.GaussianNoise(0.2),\n",
    "  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.densenet.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.DenseNet201(input_shape=(img_height, img_width, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = base_model(image_batch)\n",
    "# print(feature_batch.shape)\n",
    "\n",
    "base_model.trainable = False\n",
    "# base_model.summary()\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "# print(feature_batch_average.shape)\n",
    "\n",
    "prediction_layer = tf.keras.layers.Dense(7, activation='softmax')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "# print(prediction_batch.shape)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a global average pooling layer to the base model\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add a dropout layer to reduce overfitting\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final output layer with 7 units and softmax activation\n",
    "predictions = tf.keras.layers.Dense(7, activation='softmax')(x)\n",
    "\n",
    "# Combine the base model and the new output layers\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 7\n",
    "adam = Adam(learning_rate=0.1, decay=1e-6)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tfa.metrics.F1Score(num_classes=nb_classes, average='macro')])\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint('model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "red_plateu = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath='model.hdf5', verbose=1, save_best_only=True, monitor='val_loss')\n",
    "callbacks = [checkpointer, early_stopping, red_plateu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(training_dataset,\n",
    "          batch_size=batch_size,\n",
    "        #   steps_per_epoch=training_batches,\n",
    "          epochs=epochs,\n",
    "        #   validation_split=0.2,\n",
    "          validation_data=validation_dataset,\n",
    "          validation_steps=validation_batches,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_gozu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar la historia\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "EPOCAS = 17\n",
    "\n",
    "\n",
    "def graficar(h):\n",
    "    LOSS = 0\n",
    "    ACCURACY = 1\n",
    "    entrenamiento = np.zeros((2, EPOCAS))\n",
    "    prueba = np.zeros((2, EPOCAS))\n",
    "    entrenamiento[LOSS] = h.history['loss']  # loss de entrenamiento\n",
    "    prueba[LOSS] = h.history['val_loss']    # loss de validación\n",
    "    entrenamiento[ACCURACY] = h.history['accuracy']  # acc de entrenamiento\n",
    "    prueba[ACCURACY] = h.history['val_accuracy']  # acc de validación\n",
    "    epocas = range(1, EPOCAS+1)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    for i, label in zip((LOSS, ACCURACY), ('perdida', 'exactitud')):\n",
    "        axs[i].plot(epocas, entrenamiento[i], 'b-', label='Entrenamiento '+label)\n",
    "        axs[i].plot(epocas, prueba[i], 'y-', label='Prueba '+label)\n",
    "        axs[i].set_title('Entrenamiento y prueba ' + label)\n",
    "        axs[i].set_xlabel('Epocas')\n",
    "        axs[i].set_ylabel(label)\n",
    "        axs[i].legend()\n",
    "    plt.show()\n",
    "\n",
    "graficar(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación y Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "for images, labels in training_dataset:\n",
    "    X_train.append(images.numpy())\n",
    "    y_train.append(labels.numpy())\n",
    "\n",
    "for images,labels in test_dataset:\n",
    "    X_test.append(images.numpy())\n",
    "    y_test.append(labels.numpy())\n",
    "\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "\n",
    "# Necesito crear la variable X, que es la concatenación de X_Train con y_train y lo mismo con X_test y y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_train, X_test))\n",
    "y = np.concatenate((y_train, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=2,shuffle=True)\n",
    "#puntuación (accuracy) con cada subconjunto de validación\n",
    "\n",
    "punt_vc = []\n",
    "for entr, prue in kfold.split(X,np.zeros(shape=(X_train, 1))):\n",
    "  modelo = Sequential()\n",
    "  modelo.add(Dense(256, input_dim=777, activation='relu'))\n",
    "  modelo.add(Dense(32,activation='relu'))\n",
    "  modelo.add(Dropout(0.3)) #El 30% de los pesos se hacen igual a cero\n",
    "  modelo.add(Dense(7,activation='softmax'))\n",
    "  modelo.compile(loss='categorical_crossentropy',optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "  modelo.fit(X_train[entr], y_train[entr], epochs=10, batch_size=64, verbose=0)\n",
    "  punt = modelo.evaluate(X_test[prue], y_test[prue],verbose=0)\n",
    "  print(\"%s: %.2f%%\" % (modelo.metrics_names[1],punt[1]*100))\n",
    "  punt_vc.append(punt[1]*100)\n",
    "\n",
    "print(\"%.2f%% (+/-) %.2f%%\" % (numpy.mean(punt_vc),numpy.std(punt_vc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
