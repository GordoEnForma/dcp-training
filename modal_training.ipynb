{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation, Resizing, Rescaling\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GaussianNoise\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables Globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 160, 120\n",
    "train_data_dir = 'Training'\n",
    "# validation_data_dir = 'Validation'\n",
    "# test_data_dir = 'Testing'\n",
    "# nb_validation_samples = 193\n",
    "validation_data_dir = 'Testing'\n",
    "# test_data_dir = 'Validation'\n",
    "nb_validation_samples = 1511\n",
    "nb_train_samples = 7470\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicación: Instanciamos ImageDataGenerator para el conjunto de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   vertical_flip=False,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.1,\n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   brightness_range=[0.5, 1.0],\n",
    "                                   horizontal_flip=True\n",
    "                                   )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicación: Generamos batches de imágenes a partir de los directorios especificados utilizando flow_from_directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.keras.utils.image_dataset_from_directory(train_data_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            label_mode='categorical',\n",
    "                                                            image_size=(img_width, img_height),)\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_data_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            label_mode='categorical',\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            image_size=(img_width, img_height),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "# test_batches = tf.data.experimental.cardinality(test_dataset)\n",
    "training_batches = tf.data.experimental.cardinality(training_dataset)\n",
    "print('Number of train batches: %d' % tf.data.experimental.cardinality(training_dataset))\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size=(img_width, img_height),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicación: Cargamos la arquitectura InceptionV3 desde el módulo de aplicaciones de Keras, con pesos preentrenados en ImageNet, pero sin incluir la capa superior (fully connected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.DenseNet201(\n",
    "    weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "base_model.trainable = False\n",
    "# Descongelar las últimas 30 capas\n",
    "# for layer in base_model.layers[-100:]:\n",
    "#     layer.trainable = True\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicación: Congelamos las capas del modelo base InceptionV3 para que no se actualicen durante el entrenamiento. Transfer Learning. Sólo se actualizarán los pesos de las capas personalizadas. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicación: Añadimos capas personalizadas a la salida de la arquitectura base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Probando Actualmente\n",
    "model = Sequential( [base_model,\n",
    "                     GlobalAveragePooling2D(),\n",
    "                        Dense(512, activation='relu'),\n",
    "                        Dropout(0.5),\n",
    "                        Dense(7, activation='softmax')\n",
    "                    ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(1024, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 7\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Original\n",
    "nb_classes = 7\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "predictions = Dense(nb_classes, activation='softmax')(x)\n",
    " \n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ChatGPT approach\n",
    "nb_classes = 7\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kenny's approach\n",
    "nb_classes = 7\n",
    "\n",
    "inputs = tf.keras.Input(shape=(img_width, img_height, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs=outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicación: Compilamos el modelo con el optimizador Adam, la pérdida de entropía cruzada categórica y la precisión como métrica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 7\n",
    "adam = Adam(learning_rate=0.1, decay=1e-5)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tfa.metrics.F1Score(num_classes=nb_classes, average='macro')])\n",
    "# model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicación: Creamos un callback de ModelCheckpoint para guardar el modelo con la mejor precisión en el conjunto de validación durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint('model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "red_plateu = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.00001)\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath='model.hdf5', verbose=1, save_best_only=True, monitor='val_loss')\n",
    "callbacks = [checkpointer, early_stopping, red_plateu]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicación: Entrenamos el modelo con el método fit_generator utilizando los generadores de imágenes creados antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "          batch_size=batch_size,\n",
    "        #   steps_per_epoch=nb_train_samples//batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=nb_validation_samples//batch_size,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_validation_samples//batch_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicación: Finalmente, guardamos el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_gozu.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
